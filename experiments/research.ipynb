{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3lBfjE8k5NQ"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFY9N2oYO0SP"
      },
      "outputs": [],
      "source": [
        "! pip install pandas  -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hkVkuU_ME4H",
        "outputId": "42237e81-4c3b-4238-e502-38de7a0f994f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'text-classifier' already exists and is not an empty directory.\n",
            "/content/text-classifier\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/solumnsilence/text-classifier.git --branch dev\n",
        "%cd text-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c9DlBARkAVw",
        "outputId": "5db0b978-a854-4f16-e6e6-bab0103cf275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/cointegrated_rubert-tiny2. Creating a new one with MEAN pooling.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_st = SentenceTransformer('cointegrated/rubert-tiny2')\n",
        "\n",
        "def get_embedding(text):\n",
        "  return model_st.encode(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lce5kQxOxbv",
        "outputId": "6cf6a11e-c4ef-4554-f888-f86b3e8acb0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38740, 3), (26260, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "test_data = pd.read_csv('data/test.csv')\n",
        "\n",
        "train_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SVVt1_JPc3Q",
        "outputId": "d23fc821-5747-45aa-a674-9647243a07bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 38740/38740 [15:23<00:00, 41.97it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "features = []\n",
        "targets = train_data['category'].tolist()\n",
        "\n",
        "for i in tqdm(range(train_data.shape[0])):\n",
        "  features.append(get_embedding(train_data.loc[i, 'text']).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7EhKwcwT37m",
        "outputId": "18524b39-f857-4544-d70a-2b636c903a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxDqX_XFT39Y"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X = features\n",
        "y = targets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "\n",
        "\n",
        "classifier = KNeighborsClassifier(3).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJClZIJJXgt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9249d6-efe8-4300-8f6a-6690e173ecd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6038203407330924"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "sum(classifier.predict(X_test)==y_test) / len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZiNRZFlo8x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Результаты исследования:\n",
        "\n",
        "Я использовал предобученную нейронную сеть bert для русккого языка для получения фичей из текста и обучал алгоритмы классификации. В качестве feature extractor тестировал модели [rubert-tiny2](https://huggingface.co/cointegrated/) и [rubert-base-cased](https://huggingface.co/DeepPavlov/rubert-base-cased/) с алгоритмами knn и random forest.\n",
        "После подбора гиперпараметров к алгоритмам классификации, лучшая точность с feature extractor rubert-tiny2 было 65%, а с rubert-base-cased 75%. Был выбран второй feature extractor и knn алгоритм т.к. random forest не давал значимого улучшения.\n",
        "\n",
        "# Возможные улучшения\n",
        "\n",
        "1. Нужно больше погружаться в домен и делать препроцессинг текста. (К примеру удалить все названия и имена из предложений)\n",
        "2. Дообучить нейронку на текущей задаче\n",
        "3. Попробовать другие feature extractors, однако нужно учитывать ограничения системы и её нагрузку\n",
        "4. Лучший подбор гиперпараметров к классификаторам может дать небольшой прирост в точности.\n",
        "\n",
        "P.S. часть ноутбука не сохранилась где тренировалась моделька, используемая в приложении"
      ],
      "metadata": {
        "id": "76RPSlPQo9SL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D6-fG5SirY9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}